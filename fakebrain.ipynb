{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('stations_data.csv', sep=',')\n",
    "def map_to_five(x):\n",
    "    return min(x, 5)\n",
    "df['rounded_last_update_5mins'] = pd.to_datetime(df['rounded_last_update_5mins'])\n",
    "df['time_as_fraction'] = df['rounded_last_update_5mins'].dt.hour * 3600 + df['rounded_last_update_5mins'].dt.minute * 60 + df['rounded_last_update_5mins'].dt.second\n",
    "weekday=df['rounded_last_update_5mins'].dt.dayofweek\n",
    "weekdaydf = pd.get_dummies(weekday, prefix='day_of_week')\n",
    "df = pd.concat([df, weekdaydf], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['number', 'name', 'position_lat', 'position_lng', 'available_bikes',\n",
      "       'available_bike_stands', 'rounded_last_update',\n",
      "       'rounded_last_update_5mins', 'temp', 'feels_like', 'humidity',\n",
      "       'rain_1h', 'weather_desc', 'weather_brief', 'wind_speed', 'weatherid',\n",
      "       'time_as_fraction', 'day_of_week_0', 'day_of_week_1', 'day_of_week_2',\n",
      "       'day_of_week_3', 'day_of_week_4', 'day_of_week_5', 'day_of_week_6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Convert these seconds to a fraction of the day\n",
    "df['time_as_fraction'] = df['time_as_fraction'] / 86400\n",
    "# Applying the function to the 'available_bike_stands' column\n",
    "#y_set = pd.DataFrame(df['available_bike_stands'].apply(map_to_five))\n",
    "y_set = df['available_bike_stands']\n",
    "y_set =  pd.DataFrame(y_set)\n",
    "# Ensure x_set is in the correct shape\n",
    "x_set = df[['number','time_as_fraction','day_of_week_0','day_of_week_1','day_of_week_2','day_of_week_3','day_of_week_4','day_of_week_5','day_of_week_6','temp','feels_like']]\n",
    "#x_set =df.select_dtypes(include=['number'])\n",
    "print(df.columns)\n",
    "#x_set = df[['number','time_as_fraction','temp','feels_like']]\n",
    "#x_set = df.drop(['available_bike_stands',\"name\",\"weather_desc\",\"weather_brief\",], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# For the remainder dataset, separate X and Y as you did initially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  71  72  73  74\n",
      "  75  76  77  78  79  80  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111\n",
      " 112 113 114 115 116 117]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['number', 'time_as_fraction', 'day_of_week_0', 'day_of_week_1',\n",
       "       'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'day_of_week_5',\n",
       "       'day_of_week_6', 'temp', 'feels_like'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_number = x_set['number'].unique()\n",
    "print(station_number)\n",
    "x_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        available_bike_stands\n",
      "0                          30\n",
      "1                          30\n",
      "2                          30\n",
      "3                          29\n",
      "4                          29\n",
      "...                       ...\n",
      "622716                     40\n",
      "622717                     40\n",
      "622718                     40\n",
      "622719                     40\n",
      "622720                     40\n",
      "\n",
      "[622721 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxv = y_set.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thede\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\normalization.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.0377 - categorical_accuracy: 0.0377 - loss: 9.1687 - mse: 0.0296\n",
      "Epoch 2/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.0698 - categorical_accuracy: 0.0698 - loss: 4.4218 - mse: 0.0251\n",
      "Epoch 3/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.0800 - categorical_accuracy: 0.0800 - loss: 3.5030 - mse: 0.0237\n",
      "Epoch 4/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.0974 - categorical_accuracy: 0.0974 - loss: 3.3711 - mse: 0.0234\n",
      "Epoch 5/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.1064 - categorical_accuracy: 0.1064 - loss: 3.2889 - mse: 0.0233\n",
      "Epoch 6/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.1129 - categorical_accuracy: 0.1129 - loss: 3.2568 - mse: 0.0232\n",
      "Epoch 7/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.1233 - categorical_accuracy: 0.1233 - loss: 3.1901 - mse: 0.0231\n",
      "Epoch 8/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.1124 - categorical_accuracy: 0.1124 - loss: 3.1933 - mse: 0.0232\n",
      "Epoch 9/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.1203 - categorical_accuracy: 0.1203 - loss: 3.1666 - mse: 0.0231\n",
      "Epoch 10/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.1280 - categorical_accuracy: 0.1280 - loss: 3.1630 - mse: 0.0231\n",
      "Epoch 11/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.1169 - categorical_accuracy: 0.1169 - loss: 3.1532 - mse: 0.0231\n",
      "Epoch 12/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.1266 - categorical_accuracy: 0.1266 - loss: 3.1494 - mse: 0.0231\n",
      "Epoch 13/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.1235 - categorical_accuracy: 0.1235 - loss: 3.1350 - mse: 0.0230\n",
      "Epoch 14/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.1161 - categorical_accuracy: 0.1161 - loss: 3.1451 - mse: 0.0231\n",
      "Epoch 15/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.1271 - categorical_accuracy: 0.1271 - loss: 3.1290 - mse: 0.0230\n",
      "Epoch 16/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.1211 - categorical_accuracy: 0.1211 - loss: 3.1288 - mse: 0.0230\n",
      "Epoch 17/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.1213 - categorical_accuracy: 0.1213 - loss: 3.1260 - mse: 0.0230\n",
      "Epoch 18/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.1220 - categorical_accuracy: 0.1220 - loss: 3.1140 - mse: 0.0230\n",
      "Epoch 19/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.1239 - categorical_accuracy: 0.1239 - loss: 3.1023 - mse: 0.0230\n",
      "Epoch 20/20\n",
      "\u001b[1m929/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.1182 - categorical_accuracy: 0.1182 - loss: 3.1172 - mse: 0.0230\n",
      "83/83 - 0s - 2ms/step - accuracy: 0.1276 - categorical_accuracy: 0.1276 - loss: 3.1229 - mse: 0.0230\n",
      "Model evaluation on remainder set: [3.122901678085327, 0.12756264209747314, 0.12756264209747314, 0.023026902228593826]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6807 is out of bounds for axis 0 with size 5164",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m remainder_x \u001b[38;5;241m=\u001b[39m x_set_num\u001b[38;5;241m.\u001b[39mdrop(train_x\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ensure that y_set is correctly indexed and matched\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43my_set_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     19\u001b[0m remainder_y \u001b[38;5;241m=\u001b[39m y_set_num[remainder_x\u001b[38;5;241m.\u001b[39mindex]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Define model as before...\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6807 is out of bounds for axis 0 with size 5164"
     ]
    }
   ],
   "source": [
    "for num in station_number:\n",
    "    x_set_num = x_set.loc[x_set['number'] == num]\n",
    "    y_set_num = y_set[x_set['number'] == num]\n",
    "    \n",
    "    # Drop 'number' column correctly\n",
    "    x_set_num = x_set_num.drop('number', axis=1)\n",
    "    \n",
    "    # One-hot encode correctly\n",
    "    y_set_num = to_categorical(y_set_num, num_classes=41)  # Ensure num_classes matches your model's output\n",
    "    \n",
    "    # Convert to DataFrame if necessary (may not be needed if using TensorFlow/Keras directly)\n",
    "    # y_set_num = pd.DataFrame(y_set_num)\n",
    "    \n",
    "    train_x = x_set_num.sample(frac=.8, replace=True)\n",
    "    remainder_x = x_set_num.drop(train_x.index)\n",
    "\n",
    "    # Ensure that y_set is correctly indexed and matched\n",
    "    y_train = y_set_num[train_x.index]\n",
    "    remainder_y = y_set_num[remainder_x.index]\n",
    "    \n",
    "    # Define model as before...\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Normalization(input_shape=[10,], axis=None),\n",
    "        tf.keras.layers.Dense(1000, activation='relu'),\n",
    "        tf.keras.layers.Dense(41, activation='softmax', use_bias=True)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy', 'mse', 'categorical_accuracy'])\n",
    "    \n",
    "    # Fit model using correctly shaped data\n",
    "    model.fit(train_x, y_train, epochs=20, batch_size=5)\n",
    "    \n",
    "    # Evaluate model using correctly shaped data\n",
    "    evaluation = model.evaluate(remainder_x, remainder_y, verbose=2)\n",
    "    print(f\"Model evaluation on remainder set: {evaluation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
